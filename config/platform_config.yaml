# =============================================================================
# FREQ AI Platform Configuration - UPDATED January 2026
# =============================================================================
# CHANGE LOG:
# - Switched PRIMARY to Anthropic Direct API (Bedrock quota issues)
# - Added Google AI Studio for Gemini 3.0 models
# - AWS Bedrock DISABLED until quota resolves
# =============================================================================

providers:
  # PRIMARY: Anthropic Direct API (Opus 4.5)
  # Most reliable access - no quota issues, same pricing as Bedrock
  # Get API key: https://console.anthropic.com/
  anthropic_direct:
    enabled: true
    priority: 1  # PRIMARY
    base_url: https://api.anthropic.com
    api_key_env: ANTHROPIC_API_KEY  # export ANTHROPIC_API_KEY="sk-ant-..."
    timeout_seconds: 120
    max_retries: 3
    retry_delay_base: 1.0
    health_check_interval: 60
    max_consecutive_failures: 3

    models:
      opus-4.5:
        model_id: "claude-opus-4-5-20251101"
        max_tokens: 8192
        context_window: 200000
        cost_input_per_million: 5.0
        cost_output_per_million: 25.0
      sonnet-4.5:
        model_id: "claude-sonnet-4-5-20251101"
        max_tokens: 8192
        context_window: 200000
        cost_input_per_million: 3.0
        cost_output_per_million: 15.0
      haiku-4.5:
        model_id: "claude-haiku-4-5-20251101"
        max_tokens: 8192
        context_window: 200000
        cost_input_per_million: 0.25
        cost_output_per_million: 1.25

  # SECONDARY: Google AI Studio (Gemini 3.0)
  # Cost-efficient for high-volume operations (SIL, SA, TOM)
  # Get API key: https://aistudio.google.com/apikey
  google_ai_studio:
    enabled: true
    priority: 2  # SECONDARY
    base_url: https://generativelanguage.googleapis.com
    api_key_env: GOOGLE_AI_API_KEY  # export GOOGLE_AI_API_KEY="AIza..."
    timeout_seconds: 120
    max_retries: 3

    models:
      gemini-3-pro:
        model_id: "gemini-3.0-pro-preview"
        max_tokens: 8192
        context_window: 1000000
        cost_input_per_million: 2.0
        cost_output_per_million: 12.0
      gemini-3-flash:
        model_id: "gemini-3.0-flash"
        max_tokens: 8192
        context_window: 1000000
        cost_input_per_million: 0.50
        cost_output_per_million: 3.0
      gemini-3-thinking:
        model_id: "gemini-3.0-thinking-preview"
        max_tokens: 8192
        context_window: 1000000
        cost_input_per_million: 2.0
        cost_output_per_million: 12.0

  # DISABLED: AWS Bedrock (quota issues - ThrottlingException)
  # Status: Daily token quota exceeded/set to 0
  # To re-enable:
  #   1. Open AWS Support case to request quota increase (~48hrs)
  #   2. Try different region (us-west-2 may have higher quota)
  #   3. Consider Provisioned Throughput for guaranteed capacity
  aws_bedrock:
    enabled: false  # DISABLED - quota issues
    priority: 3  # FALLBACK when fixed
    region: us-east-1
    inference_profile: global
    timeout_seconds: 120
    max_retries: 3

    models:
      opus-4.5:
        model_id: "global.anthropic.claude-opus-4-5-20251101-v1:0"
        max_tokens: 8192
        context_window: 200000
      sonnet-4.5:
        model_id: "global.anthropic.claude-sonnet-4-5-20251101-v1:0"
        max_tokens: 8192
        context_window: 200000
      haiku-4.5:
        model_id: "global.anthropic.claude-haiku-4-5-20251101-v1:0"
        max_tokens: 8192
        context_window: 200000

    # Enterprise features (available when re-enabled)
    features:
      tool_search: true
      tool_use_examples: true
      effort_parameter: high
      persistent_memory: true
      session_isolation: true

  # TERTIARY: Google Cloud Vertex AI
  # Alternative to AI Studio with GCP integration
  vertex_ai:
    enabled: false  # Use google_ai_studio instead (simpler setup)
    priority: 4
    region: us-central1
    project_id_env: GCP_PROJECT_ID
    timeout_seconds: 120
    max_retries: 3

    models:
      gemini-3-thinking:
        model_id: "gemini-3.0-thinking-preview"
        max_tokens: 8192
        context_window: 1000000
      gemini-3-pro:
        model_id: "gemini-3.0-pro-preview"
        max_tokens: 8192
        context_window: 1000000
      gemini-3-flash:
        model_id: "gemini-3.0-flash-preview"
        max_tokens: 8192
        context_window: 1000000

  # LAST RESORT: Azure Foundry
  azure_foundry:
    enabled: false
    priority: 5
    timeout_seconds: 120
    max_retries: 3

# =============================================================================
# SUBSTRATE MAPPINGS - UPDATED
# =============================================================================
# SSC/CGE: Opus 4.5 (Anthropic Direct) - maximum cognitive capability
# SIL/SA/TOM: Gemini 3.0 Flash (Google AI) - cost efficient, fast

substrate_mappings:
  # Level 1: Strategic Synthesis Core
  # Maximum cognitive capability - Opus 4.5 via Anthropic Direct
  L1_SSC:
    primary_provider: anthropic_direct
    primary_model: opus-4.5
    fallback_provider: google_ai_studio
    fallback_model: gemini-3-thinking
    temperature: 0.7
    max_tokens: 8192
    strict_mode: false

  # Level 2: Cognitive Governance Engine
  # Deterministic governance - Opus 4.5 STRICT MODE
  L2_CGE:
    primary_provider: anthropic_direct
    primary_model: opus-4.5
    fallback_provider: google_ai_studio
    fallback_model: gemini-3-pro
    temperature: 0.0  # STRICT MODE for deterministic decisions
    max_tokens: 4096
    strict_mode: true

  # Level 3: Strategic Intelligence Lead
  # Knowledge retrieval - Flash for speed and cost
  L3_SIL:
    primary_provider: google_ai_studio
    primary_model: gemini-3-flash
    fallback_provider: anthropic_direct
    fallback_model: sonnet-4.5
    temperature: 0.3
    max_tokens: 4096
    strict_mode: false

  # Level 4: System Architect
  # Technical design - Pro for capability
  L4_SA:
    primary_provider: google_ai_studio
    primary_model: gemini-3-pro
    fallback_provider: anthropic_direct
    fallback_model: sonnet-4.5
    temperature: 0.5
    max_tokens: 8192
    strict_mode: false

  # Level 5: Runtime Realization Node (TOM)
  # Execution layer - Flash for speed (<2000ms FREQ LAW)
  L5_TOM:
    primary_provider: google_ai_studio
    primary_model: gemini-3-flash
    fallback_provider: anthropic_direct
    fallback_model: haiku-4.5
    temperature: 0.3
    max_tokens: 2048
    strict_mode: false

# =============================================================================
# ESTIMATED MONTHLY COSTS (Hybrid Approach)
# =============================================================================
# Assuming 1M tokens/day for SSC/CGE (Opus), 5M tokens/day for SIL/SA/TOM (Gemini)
#
# Opus 4.5 (SSC/CGE):     1M × 30 days × ($5 + $25) / 1M = $900/month
# Gemini 3 Flash (others): 5M × 30 days × ($0.50 + $3) / 1M = $525/month
# ----------------------------------------------------------------
# TOTAL ESTIMATED:                                         ~$1,425/month
#
# vs. Pure Opus 4.5:      6M × 30 days × $30 / 1M =         $5,400/month
# SAVINGS:                                                  ~74%
# =============================================================================

# =============================================================================
# FAILOVER SETTINGS
# =============================================================================

failover:
  enabled: true
  timeout_ms: 5000
  max_attempts: 3
  circuit_breaker:
    enabled: true
    failure_threshold: 5
    reset_timeout_seconds: 60
    half_open_max_calls: 3

# =============================================================================
# FREQ LAW COMPLIANCE TARGETS
# =============================================================================

freq_law:
  fast:
    target_latency_ms: 2000
    warning_threshold_ms: 1500
  robust:
    quorum_threshold: 0.75
    min_healthy_providers: 2
    bft_enabled: true
  evolutionary:
    max_retry_attempts: 3
    deviation_threshold_percent: 2
    reflexion_enabled: true
  quantified:
    trust_score_target: 0.95
    audit_all_operations: true
    provenance_format: json-ld

# =============================================================================
# UI/UX SETTINGS
# =============================================================================

ui:
  theme:
    default_mode: dark
    design_system: carbon

  dashboard:
    refresh_interval_seconds: 5
    max_audit_entries: 100
    show_latency_chart: true
    show_topology_graph: true

  accessibility:
    wcag_level: AA
    high_contrast_available: true
    keyboard_navigation: true
    screen_reader_support: true

# =============================================================================
# OBSERVABILITY
# =============================================================================

observability:
  logging:
    level: INFO
    format: json
    include_timestamps: true
    include_trace_ids: true

  metrics:
    enabled: true
    export_interval_seconds: 30
    labels:
      - provider
      - model
      - node_type
      - operation

  tracing:
    enabled: true
    sample_rate: 1.0
    exporter: otlp

# =============================================================================
# REQUIRED ENVIRONMENT VARIABLES
# =============================================================================
# Set these before running:
#
# # Anthropic Direct API (PRIMARY)
# export ANTHROPIC_API_KEY="sk-ant-api03-..."
#
# # Google AI Studio (SECONDARY)
# export GOOGLE_AI_API_KEY="AIzaSy..."
#
# # AWS (OPTIONAL - when Bedrock quota resolves)
# export AWS_ACCESS_KEY_ID="AKIA..."
# export AWS_SECRET_ACCESS_KEY="..."
# export AWS_REGION="us-east-1"
# =============================================================================
